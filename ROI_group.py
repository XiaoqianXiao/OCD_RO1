#!/usr/bin/env python3
"""
ROI-to-ROI Functional Connectivity Group Analysis using Customizable Atlas

This script performs group-level statistical analysis on ROI-to-ROI functional connectivity data
using any user-specified atlas. It compares healthy controls (HC) vs. OCD patients
and performs longitudinal analyses.

The script is compatible with both custom atlases and Nilearn built-in atlases (e.g., Schaefer 2018,
Harvard-Oxford, Power 2011, etc.) as generated by the updated ROI_1st.py script.

Author: [Your Name]
Date: [Current Date]

USAGE EXAMPLES:
==============

1. With Custom Atlas (e.g., Harvard-Oxford):
   python ROI_group.py \
     --subjects_csv /path/to/group.csv \
     --clinical_csv /path/to/clinical.csv \
     --atlas-name harvardoxford

2. With Nilearn Atlas (e.g., Schaefer 2018):
   python ROI_group.py \
     --subjects_csv /path/to/group.csv \
     --clinical_csv /path/to/clinical.csv \
     --atlas-name schaefer_2018_400_7_2

3. With Custom Output Directory:
   python ROI_group.py \
     --subjects_csv /path/to/group.csv \
     --clinical_csv /path/to/clinical.csv \
     --atlas-name power_2011 \
     --output_dir /custom/output/path

4. With Custom Input Directory:
   python ROI_group.py \
     --subjects_csv /path/to/group.csv \
     --clinical_csv /path/to/clinical.csv \
     --atlas-name aal \
     --input_dir /custom/input/path

ATLAS NAMING CONVENTIONS:
========================

The script automatically detects atlas names from the input files. Atlas names are derived from:

Custom Atlases:
- If --atlas-name is specified: uses that name
- Otherwise: uses the atlas filename without extension

Nilearn Atlases:
- If --atlas-name is specified: uses that name
- Otherwise: automatically generates name from parameters (e.g., schaefer_2018_400_7_2)

OUTPUT FILES:
=============

- group_diff_baseline_roi_fc.csv: Group difference analysis results (HC vs OCD)
- baselineFC_vs_deltaYBOCS_roi_fc.csv: Baseline FC vs symptom change regression
- deltaFC_vs_deltaYBOCS_roi_fc.csv: FC change vs symptom change regression

REQUIREMENTS:
=============

- Group metadata CSV with 'sub' and 'group' columns
- Clinical data CSV with 'sub', 'ybocs_baseline', 'ybocs_followup' columns
- ROI-to-ROI FC data files from ROI_1st.py analysis
- Consistent atlas naming across all input files
"""

import os
import glob
import numpy as np
import pandas as pd
from scipy import stats
from statsmodels.stats.multitest import fdrcorrection
import argparse
import logging
from pathlib import Path
from typing import Optional, Tuple, List, Dict, Any
import warnings
import re
import sys

# Suppress warnings for cleaner output
warnings.filterwarnings('ignore')

# =============================================================================
# CONFIGURATION
# =============================================================================

# Default configuration
DEFAULT_CONFIG = {
    'output_dir': '/project/6079231/dliang55/R01_AOCD/ROI_group',
    'input_dir': '/input',
    'log_file': 'roi_to_roi_group_analysis.log',
    'sessions': ['ses-baseline', 'ses-followup'],
    'min_subjects_per_group': 2,
    'fdr_alpha': 0.05,
    'default_atlas_name': 'harvardoxford'  # Fallback atlas name
}

# =============================================================================
# LOGGING SETUP
# =============================================================================

def setup_logging(output_dir: str, log_filename: str) -> logging.Logger:
    """Set up logging configuration with both file and console handlers."""
    log_file = os.path.join(output_dir, log_filename)
    log_dir = os.path.dirname(log_file)
    os.makedirs(log_dir, exist_ok=True)
    
    # Create formatter
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # Create logger
    logger = logging.getLogger('ROI_Group_Analysis')
    logger.setLevel(logging.INFO)
    
    # Clear existing handlers
    logger.handlers.clear()
    
    # File handler
    file_handler = logging.FileHandler(log_file)
    file_handler.setLevel(logging.INFO)
    file_handler.setFormatter(formatter)
    
    # Console handler
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(formatter)
    
    # Add handlers
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    return logger

# =============================================================================
# ARGUMENT PARSING
# =============================================================================

def parse_arguments() -> argparse.ArgumentParser:
    """Parse command-line arguments."""
    parser = argparse.ArgumentParser(
        description='ROI-to-ROI functional connectivity group analysis using customizable atlas',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # With Custom Atlas (e.g., Harvard-Oxford)
  python ROI_group.py \\
    --subjects_csv /path/to/group.csv \\
    --clinical_csv /path/to/clinical.csv \\
    --atlas-name harvardoxford

  # With Nilearn Atlas (e.g., Schaefer 2018)
  python ROI_group.py \\
    --subjects_csv /path/to/group.csv \\
    --clinical_csv /path/to/clinical.csv \\
    --atlas-name schaefer_2018_400_7_2

  # With Custom Directories
  python ROI_group.py \\
    --subjects_csv /path/to/group.csv \\
    --clinical_csv /path/to/clinical.csv \\
    --atlas-name power_2011 \\
    --output_dir /custom/output/path \\
    --input_dir /custom/input/path

Run with --help for full help.
        """
    )
    parser.add_argument(
        '--subjects_csv', 
        type=str, 
        required=True, 
        help='Path to group.csv file'
    )
    parser.add_argument(
        '--clinical_csv', 
        type=str, 
        required=True, 
        help='Path to clinical.csv file'
    )
    parser.add_argument(
        '--atlas_name', 
        type=str, 
        help='Name of the atlas used in the analysis (e.g., harvardoxford, schaefer_2018_400_7_2, power_2011). If not specified, will be auto-detected from input files.'
    )
    parser.add_argument(
        '--output_dir', 
        type=str, 
        default=DEFAULT_CONFIG['output_dir'],
        help='Output directory for results'
    )
    parser.add_argument(
        '--input_dir', 
        type=str, 
        default=DEFAULT_CONFIG['input_dir'],
        help='Input directory for FC data'
    )
    parser.add_argument(
        '--verbose', '-v', 
        action='store_true', 
        help='Enable verbose logging'
    )
    
    return parser.parse_args()

# =============================================================================
# ATLAS DETECTION AND VALIDATION
# =============================================================================

def detect_atlas_name_from_files(input_dir: str, logger: logging.Logger) -> str:
    """Auto-detect atlas name from available FC files."""
    logger.info("Auto-detecting atlas name from input directory: %s", input_dir)
    
    if not os.path.exists(input_dir):
        logger.warning("Input directory does not exist, using default atlas name: %s", DEFAULT_CONFIG['default_atlas_name'])
        return DEFAULT_CONFIG['default_atlas_name']
    
    # Look for FC files with different atlas patterns
    fc_patterns = [
        '*_task-rest_*_pairwise_fc_avg.csv',  # General pattern
        '*_task-rest_*_roiroi_matrix_avg.npy'  # Matrix files
    ]
    
    detected_atlases = set()
    
    for pattern in fc_patterns:
        files = glob.glob(os.path.join(input_dir, pattern))
        for file_path in files:
            filename = os.path.basename(file_path)
            # Extract atlas name from filename
            # Pattern: sub-XXX_ses-XXX_task-rest_ATLAS_NAME_roiroi_matrix_avg.npy
            # or: sub-XXX_ses-XXX_task-rest_ATLAS_NAME_pairwise_fc_avg.csv
            match = re.search(r'_task-rest_(.+?)_(?:roiroi_matrix|pairwise_fc)_avg', filename)
            if match:
                atlas_name = match.group(1)
                detected_atlases.add(atlas_name)
                logger.debug("Detected atlas name '%s' from file: %s", atlas_name, filename)
    
    if not detected_atlases:
        logger.warning("No atlas names detected, using default: %s", DEFAULT_CONFIG['default_atlas_name'])
        return DEFAULT_CONFIG['default_atlas_name']
    
    if len(detected_atlases) > 1:
        logger.warning("Multiple atlas names detected: %s. Using first one: %s", detected_atlases, list(detected_atlases)[0])
        return list(detected_atlases)[0]
    
    detected_atlas = list(detected_atlases)[0]
    logger.info("Auto-detected atlas name: %s", detected_atlas)
    return detected_atlas

def validate_atlas_name(atlas_name: str, input_dir: str, logger: logging.Logger) -> bool:
    """Validate that the specified atlas name exists in input files."""
    logger.info("Validating atlas name: %s", atlas_name)
    
    if not os.path.exists(input_dir):
        logger.error("Input directory does not exist: %s", input_dir)
        return False
    
    # Check for files with this atlas name
    fc_pattern = os.path.join(input_dir, f'*_task-rest_{atlas_name}_pairwise_fc_avg.csv')
    matrix_pattern = os.path.join(input_dir, f'*_task-rest_{atlas_name}_roiroi_matrix_avg.npy')
    
    fc_files = glob.glob(fc_pattern)
    matrix_files = glob.glob(matrix_pattern)
    
    total_files = len(fc_files) + len(matrix_files)
    
    if total_files == 0:
        logger.error("No files found for atlas name '%s' in directory: %s", atlas_name, input_dir)
        logger.error("Expected patterns: %s, %s", fc_pattern, matrix_pattern)
        return False
    
    logger.info("Found %d files for atlas '%s' (%d FC, %d matrix)", total_files, atlas_name, len(fc_files), len(matrix_files))
    return True

# =============================================================================
# HELPER FUNCTIONS
# =============================================================================

def get_roi_fc_path(subject: str, session: str, input_dir: str, atlas_name: str) -> str:
    """Get path to pair-wise FC CSV file."""
    if not subject.startswith('sub-'):
        subject = f"sub-{subject}"
    
    return os.path.join(
        input_dir, 
        f"{subject}_{session}_task-rest_{atlas_name}_pairwise_fc_avg.csv"
    )

def get_group(subject_id: str, metadata_df: pd.DataFrame) -> Optional[str]:
    """Get group label for a subject."""
    if subject_id.startswith('sub-'):
        subject_id = subject_id.replace('sub-', '')
    
    group = metadata_df[metadata_df['subject_id'] == subject_id]['group']
    if group.empty:
        return None
    
    return group.iloc[0]

# =============================================================================
# STATISTICAL ANALYSIS FUNCTIONS
# =============================================================================

def run_ttest(
    fc_data_hc: pd.DataFrame, 
    fc_data_ocd: pd.DataFrame, 
    feature_columns: List[str],
    logger: logging.Logger
) -> pd.DataFrame:
    """Run two-sample t-tests with FDR correction for ROI-to-ROI FC."""
    logger.info("Running t-tests for %d features", len(feature_columns))
    
    results = []
    dropped_features = []
    
    for col in feature_columns:
        hc_values = fc_data_hc[col].dropna()
        ocd_values = fc_data_ocd[col].dropna()
        
        logger.debug("Feature %s: HC n=%d, OCD n=%d", col, len(hc_values), len(ocd_values))
        
        if len(hc_values) < DEFAULT_CONFIG['min_subjects_per_group'] or \
           len(ocd_values) < DEFAULT_CONFIG['min_subjects_per_group']:
            logger.warning(
                "Skipping feature %s due to insufficient data (HC n=%d, OCD n=%d)",
                col, len(hc_values), len(ocd_values)
            )
            dropped_features.append((col, f"HC n={len(hc_values)}, OCD n={len(ocd_values)}"))
            continue
        
        # Perform t-test
        t_stat, p_val = stats.ttest_ind(ocd_values, hc_values, equal_var=False)
        
        results.append({
            'Feature': col,
            't_statistic': t_stat,
            'p_value': p_val,
            'OCD_mean': np.mean(ocd_values),
            'HC_mean': np.mean(hc_values),
            'OCD_n': len(ocd_values),
            'HC_n': len(hc_values)
        })
    
    if dropped_features:
        logger.info(
            "Dropped %d features due to insufficient data: %s", 
            len(dropped_features), dropped_features
        )
    
    if not results:
        logger.info("No t-test results generated (no valid features)")
        return pd.DataFrame()
    
    # Create results DataFrame and apply FDR correction
    results_df = pd.DataFrame(results)
    p_vals = results_df['p_value'].values
    _, p_vals_corr = fdrcorrection(p_vals, alpha=DEFAULT_CONFIG['fdr_alpha'])
    results_df['p_value_fdr'] = p_vals_corr
    
    logger.info("Generated t-test results for %d features", len(results_df))
    
    return results_df

def run_regression(
    fc_data: pd.DataFrame, 
    y_values: pd.Series, 
    feature_columns: List[str],
    logger: logging.Logger
) -> pd.DataFrame:
    """Run linear regression with FDR correction for ROI-to-ROI FC."""
    logger.info("Running regressions for %d features", len(feature_columns))
    
    results = []
    dropped_features = []
    
    # Ensure consistent index types
    fc_data.index = fc_data.index.astype(str)
    y_values.index = y_values.index.astype(str)
    
    # Find common subjects
    common_subjects = fc_data.index.intersection(y_values.index)
    logger.debug("Common subjects for regression: %d", len(common_subjects))
    
    if not common_subjects.size:
        logger.warning("No common subjects for regression")
        return pd.DataFrame()
    
    # Filter data to common subjects
    fc_data = fc_data.loc[common_subjects]
    y_values = y_values.loc[common_subjects]

    # Run regression for each feature
    for col in feature_columns:
        x = fc_data[col].dropna()
        if x.empty:
            logger.warning("Skipping feature %s due to empty data", col)
            dropped_features.append((col, "empty data"))
            continue
        
        y = y_values.loc[x.index].dropna()
        logger.debug("Feature %s: n=%d", col, len(x))
        
        if len(x) < DEFAULT_CONFIG['min_subjects_per_group'] or \
           len(y) < DEFAULT_CONFIG['min_subjects_per_group']:
            logger.warning(
                "Skipping feature %s due to insufficient data (n=%d)", 
                col, len(x)
            )
            dropped_features.append((col, f"n={len(x)}"))
            continue
        
        # Perform linear regression
        x = x.values.reshape(-1, 1)
        y = y.values
        slope, intercept, r_value, p_val, _ = stats.linregress(x.flatten(), y)
        
        results.append({
            'Feature': col,
            'slope': slope,
            'intercept': intercept,
            'r_value': r_value,
            'p_value': p_val,
            'n': len(x)
        })
    
    if dropped_features:
        logger.info(
            "Dropped %d features due to insufficient data: %s", 
            len(dropped_features), dropped_features
        )
    
    if not results:
        logger.info("No regression results generated (no valid features)")
        return pd.DataFrame()
    
    # Create results DataFrame and apply FDR correction
    results_df = pd.DataFrame(results)
    p_vals = results_df['p_value'].values
    _, p_vals_corr = fdrcorrection(p_vals, alpha=DEFAULT_CONFIG['fdr_alpha'])
    results_df['p_value_fdr'] = p_vals_corr
    
    logger.info("Generated regression results for %d features", len(results_df))
    
    return results_df

# =============================================================================
# DATA LOADING AND VALIDATION
# =============================================================================

def load_and_validate_metadata(
    subjects_csv: str, 
    clinical_csv: str, 
    logger: logging.Logger
) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """Load and validate metadata CSVs."""
    logger.info("Loading metadata from %s and %s", subjects_csv, clinical_csv)
    
    try:
        df = pd.read_csv(subjects_csv)
        df['subject_id'] = df['sub'].astype(str)
        df = df[df['group'].isin(['HC', 'OCD'])]
        logger.info("Loaded %d subjects from %s", len(df), subjects_csv)
    except Exception as e:
        logger.error("Failed to load subjects CSV: %s", e)
        raise ValueError(f"Failed to load subjects CSV: {e}")

    try:
        df_clinical = pd.read_csv(clinical_csv)
        df_clinical['subject_id'] = df_clinical['sub'].astype(str)
        logger.info("Loaded %d clinical records from %s", len(df_clinical), clinical_csv)
    except Exception as e:
        logger.error("Failed to load clinical CSV: %s", e)
        raise ValueError(f"Failed to load clinical CSV: {e}")

    return df, df_clinical

def validate_subjects(
    fc_dir: str, 
    metadata_df: pd.DataFrame, 
    atlas_name: str,
    logger: logging.Logger
) -> Tuple[List[str], List[str], Dict[str, List[str]]]:
    """Validate subjects based on available pair-wise FC files."""
    logger.info("Validating subjects in FC directory %s with atlas %s", fc_dir, atlas_name)
    
    if not os.path.exists(fc_dir):
        logger.error("Input directory %s does not exist", fc_dir)
        raise ValueError(f"Input directory {fc_dir} does not exist")
    
    # Find FC files for the specific atlas
    fc_pattern = os.path.join(fc_dir, f'*_task-rest_{atlas_name}_pairwise_fc_avg.csv')
    fc_files = glob.glob(fc_pattern)
    logger.info("Found %d FC files for atlas '%s'", len(fc_files), atlas_name)
    
    if not fc_files:
        # Try alternative patterns
        alt_patterns = [
            os.path.join(fc_dir, f'*_task-rest_{atlas_name}_roiroi_matrix_avg.npy'),
            os.path.join(fc_dir, '*_task-rest_*_pairwise_fc_avg.csv'),
            os.path.join(fc_dir, '*_task-rest_*_roiroi_matrix_avg.npy')
        ]
        
        for pattern in alt_patterns:
            files = glob.glob(pattern)
            if files:
                logger.warning("No FC files found for atlas '%s', but found %d files with pattern: %s", 
                             atlas_name, len(files), pattern)
                break
        else:
            dir_contents = os.listdir(fc_dir)
            logger.warning("No FC files found in %s. Directory contents: %s", fc_dir, dir_contents)
    
    # Parse subject and session information
    subject_sessions = {}
    
    for f in fc_files:
        filename = os.path.basename(f)
        if '_ses-' not in filename or f'_task-rest_{atlas_name}_pairwise_fc_avg.csv' not in filename:
            logger.debug("Skipping invalid FC file: %s", filename)
            continue
        
        parts = filename.split('_')
        if len(parts) < 2:
            logger.debug("Skipping invalid FC filename: %s", filename)
            continue
        
        subject = parts[0].replace('sub-', '')
        session = parts[1]
        subject_sessions.setdefault(subject, []).append(session)
        logger.debug("Found subject %s, session %s in file %s", subject, session, filename)

    # Validate against metadata
    csv_subjects = set(metadata_df['subject_id'])
    file_subjects = set(subject_sessions.keys())
    
    logger.info(
        "CSV subjects: %d, FC file subjects: %d, overlap: %d",
        len(csv_subjects), len(file_subjects), len(csv_subjects & file_subjects)
    )
    
    # Determine valid subjects for different analyses
    sessions = DEFAULT_CONFIG['sessions']
    
    # Subjects valid for group analysis (need baseline)
    valid_group = [
        sid for sid in metadata_df['subject_id'] 
        if sid.replace('sub-', '') in subject_sessions and 
        'ses-baseline' in subject_sessions[sid.replace('sub-', '')]
    ]
    
    # Subjects valid for longitudinal analysis (need both sessions)
    valid_longitudinal = [
        sid for sid in metadata_df['subject_id'] 
        if sid.replace('sub-', '') in subject_sessions and 
        all(ses in subject_sessions[sid.replace('sub-', '')] for ses in sessions)
    ]
    
    logger.info("Valid subjects for group analysis: %d", len(valid_group))
    logger.info("Valid subjects for longitudinal analysis: %d", len(valid_longitudinal))
    
    return valid_group, valid_longitudinal, subject_sessions

def load_roi_fc_data(
    subject_ids: List[str], 
    session: str, 
    input_dir: str, 
    atlas_name: str,
    logger: logging.Logger
) -> Tuple[pd.DataFrame, Optional[List[str]]]:
    """Load pair-wise FC data for given subjects and session."""
    logger.info("Loading pair-wise FC data for %d subjects, session %s, atlas %s", 
               len(subject_ids), session, atlas_name)
    
    fc_data = []
    feature_columns = None
    
    for sid in subject_ids:
        sid_no_prefix = sid.replace('sub-', '')
        fc_path = get_roi_fc_path(sid_no_prefix, session, input_dir, atlas_name)
        
        if not os.path.exists(fc_path):
            logger.warning("FC file not found: %s", fc_path)
            continue
        
        try:
            fc_df = pd.read_csv(fc_path)
            logger.debug("Loaded FC file %s with %d rows", fc_path, len(fc_df))
            
            if feature_columns is None:
                feature_columns = [f"{row['ROI_1']}-{row['ROI_2']}_FC" for _, row in fc_df.iterrows()]
                logger.debug("Identified %d feature columns", len(feature_columns))
            
            # Create feature matrix
            fc_pivot = pd.DataFrame({
                f"{row['ROI_1']}-{row['ROI_2']}_FC": [row['FC']]
                for _, row in fc_df.iterrows()
            })
            fc_pivot['subject_id'] = sid_no_prefix
            fc_data.append(fc_pivot)
            
        except Exception as e:
            logger.error("Failed to process FC file %s: %s", fc_path, e)
            continue
    
    if not fc_data:
        logger.warning("No FC data loaded for session %s, atlas %s", session, atlas_name)
        return pd.DataFrame(), feature_columns
    
    fc_data_df = pd.concat(fc_data, ignore_index=True)
    logger.info("Loaded FC data for %d subjects, %d features, atlas %s", 
               len(fc_data_df), len(feature_columns), atlas_name)
    
    return fc_data_df, feature_columns

# =============================================================================
# MAIN ANALYSIS FUNCTIONS
# =============================================================================

def perform_group_analysis(
    baseline_fc_data: pd.DataFrame,
    metadata_df: pd.DataFrame,
    roi_feature_columns: List[str],
    output_dir: str,
    atlas_name: str,
    logger: logging.Logger
) -> bool:
    """Perform group difference analysis at baseline."""
    logger.info("Performing group difference analysis at baseline for atlas: %s", atlas_name)
    
    # Separate HC and OCD data
    hc_data = baseline_fc_data[
        baseline_fc_data['subject_id'].isin(metadata_df[metadata_df['group'] == 'HC']['subject_id'])
    ]
    ocd_data = baseline_fc_data[
        baseline_fc_data['subject_id'].isin(metadata_df[metadata_df['group'] == 'OCD']['subject_id'])
    ]
    
    logger.info("Group analysis: HC n=%d, OCD n=%d", len(hc_data), len(ocd_data))
    
    if hc_data.empty or ocd_data.empty:
        logger.warning(
            "Insufficient data for group analysis (HC empty: %s, OCD empty: %s)",
            hc_data.empty, ocd_data.empty
        )
        return False
    
    # Run t-tests
    ttest_results = run_ttest(hc_data, ocd_data, roi_feature_columns, logger)
    
    if not ttest_results.empty:
        output_path = os.path.join(output_dir, f'group_diff_baseline_{atlas_name}_roi_fc.csv')
        ttest_results.to_csv(output_path, index=False)
        logger.info("Saved t-test results to %s", output_path)
        return True
    else:
        logger.info("No significant t-test results to save")
        return False

def perform_longitudinal_analysis(
    baseline_fc_data: pd.DataFrame,
    metadata_df: pd.DataFrame,
    df_clinical: pd.DataFrame,
    valid_longitudinal: List[str],
    roi_feature_columns: List[str],
    input_dir: str,
    output_dir: str,
    atlas_name: str,
    logger: logging.Logger
) -> None:
    """Perform longitudinal analysis for OCD subjects."""
    logger.info("Performing longitudinal analysis for atlas: %s", atlas_name)
    
    # Prepare OCD clinical data
    ocd_df = df_clinical[
        df_clinical['subject_id'].isin(metadata_df[metadata_df['group'] == 'OCD']['subject_id'])
    ].copy()
    ocd_df['delta_ybocs'] = ocd_df['ybocs_baseline'] - ocd_df['ybocs_followup']
    
    logger.info("Longitudinal analysis: OCD subjects n=%d", len(ocd_df))

    # 1. Baseline FC vs symptom change
    baseline_fc_ocd = baseline_fc_data[
        baseline_fc_data['subject_id'].isin(ocd_df['subject_id'])
    ]
    
    logger.info("Baseline FC for OCD: n=%d", len(baseline_fc_ocd))
    
    if not baseline_fc_ocd.empty:
        regression_results = run_regression(
            baseline_fc_ocd.set_index('subject_id'),
            ocd_df.set_index('subject_id')['delta_ybocs'],
            roi_feature_columns,
            logger
        )
        
        if not regression_results.empty:
            output_path = os.path.join(output_dir, f'baselineFC_vs_deltaYBOCS_{atlas_name}_roi_fc.csv')
            regression_results.to_csv(output_path, index=False)
            logger.info("Saved baseline FC regression results to %s", output_path)
        else:
            logger.info("No significant baseline FC regression results to save")
    else:
        logger.warning("No baseline FC data for OCD subjects in longitudinal analysis")

    # 2. FC change vs symptom change
    logger.info("Analyzing FC change vs symptom change")
    fc_change_data = []
    
    for sid in valid_longitudinal:
        sid_clean = sid.replace('sub-', '')
        base_path = get_roi_fc_path(sid_clean, 'ses-baseline', input_dir, atlas_name)
        follow_path = get_roi_fc_path(sid_clean, 'ses-followup', input_dir, atlas_name)
        
        if not (os.path.exists(base_path) and os.path.exists(follow_path)):
            logger.warning(
                "Missing FC files for subject %s (baseline: %s, followup: %s)",
                sid, os.path.exists(base_path), os.path.exists(follow_path)
            )
            continue
        
        try:
            # Load baseline and followup data
            base_fc = pd.read_csv(base_path)
            follow_fc = pd.read_csv(follow_path)
            
            logger.debug(
                "Loaded baseline FC (%d rows) and followup FC (%d rows) for %s",
                len(base_fc), len(follow_fc), sid
            )
            
            # Compute FC change
            change_fc = pd.DataFrame({
                f"{row['ROI_1']}-{row['ROI_2']}_FC": [follow_fc.iloc[i]['FC'] - row['FC']]
                for i, row in base_fc.iterrows()
            })
            change_fc['subject_id'] = sid_clean
            fc_change_data.append(change_fc)
            
        except Exception as e:
            logger.error("Failed to process longitudinal FC for subject %s: %s", sid, e)
            continue

    if fc_change_data:
        fc_change_data = pd.concat(fc_change_data, ignore_index=True)
        fc_change_data['subject_id'] = fc_change_data['subject_id'].astype(str)
        
        logger.info(
            "Loaded FC change data for %d subjects, %d features",
            len(fc_change_data), len(roi_feature_columns)
        )
        
        # Run regression analysis
        regression_results = run_regression(
            fc_change_data.set_index('subject_id'),
            ocd_df.set_index('subject_id')['delta_ybocs'],
            roi_feature_columns,
            logger
        )
        
        if not regression_results.empty:
            output_path = os.path.join(output_dir, f'deltaFC_vs_deltaYBOCS_{atlas_name}_roi_fc.csv')
            regression_results.to_csv(output_path, index=False)
            logger.info("Saved FC change regression results to %s", output_path)
        else:
            logger.info("No significant FC change regression results to save")
    else:
        logger.warning("No FC change data loaded for longitudinal analysis")

# =============================================================================
# MAIN EXECUTION
# =============================================================================

def main():
    """Main function to run ROI-to-ROI functional connectivity group analysis."""
    # Parse arguments
    args = parse_arguments()
    
    # Setup logging
    logger = setup_logging(args.output_dir, DEFAULT_CONFIG['log_file'])
    if args.verbose:
        logger.setLevel(logging.DEBUG)
    
    logger.info("=" * 80)
    logger.info("Starting ROI-to-ROI Functional Connectivity Group Analysis")
    logger.info("=" * 80)
    logger.info("Arguments: %s", vars(args))
    
    try:
        # Create output directory
        os.makedirs(args.output_dir, exist_ok=True)
        
        # Determine atlas name
        if args.atlas_name:
            atlas_name = args.atlas_name
            logger.info("Using specified atlas name: %s", atlas_name)
        else:
            atlas_name = detect_atlas_name_from_files(args.input_dir, logger)
            logger.info("Auto-detected atlas name: %s", atlas_name)
        
        # Validate atlas name
        if not validate_atlas_name(atlas_name, args.input_dir, logger):
            logger.error("Atlas name validation failed")
            raise ValueError(f"Atlas name '{atlas_name}' validation failed")
        
        # Load metadata
        df, df_clinical = load_and_validate_metadata(args.subjects_csv, args.clinical_csv, logger)

        # Normalize subject IDs in metadata
        df['subject_id'] = df['subject_id'].str.replace('sub-', '')
        df_clinical['subject_id'] = df_clinical['subject_id'].str.replace('sub-', '')
        logger.debug("Normalized subject IDs in metadata")

        # Validate subjects
        valid_group, valid_longitudinal, _ = validate_subjects(args.input_dir, df, atlas_name, logger)
        
        if not valid_group and not valid_longitudinal:
            logger.error("No valid subjects found for any analysis")
            raise ValueError("No valid subjects found for any analysis.")

        # Load baseline ROI FC data
        baseline_roi_fc_data, roi_feature_columns = load_roi_fc_data(
            valid_group, 'ses-baseline', args.input_dir, atlas_name, logger
        )
        
        if baseline_roi_fc_data.empty:
            logger.warning("No baseline ROI FC data loaded. Exiting.")
            return

        # 1. Group difference at baseline
        if valid_group:
            perform_group_analysis(baseline_roi_fc_data, df, roi_feature_columns, args.output_dir, atlas_name, logger)

        # 2. Longitudinal analyses
        if valid_longitudinal:
            perform_longitudinal_analysis(
                baseline_roi_fc_data, df, df_clinical, valid_longitudinal, 
                roi_feature_columns, args.input_dir, args.output_dir, atlas_name, logger
            )

        logger.info("Main analysis completed successfully for atlas: %s", atlas_name)
    
    except Exception as e:
        logger.error("Main execution failed: %s", e)
        raise
    
    finally:
        logger.info("=" * 80)
        logger.info("ROI-to-ROI Functional Connectivity Group Analysis Completed")
        logger.info("=" * 80)

def print_quick_help():
    """Print quick help information."""
    quick_help = """
QUICK HELP - ROI-to-ROI Functional Connectivity Group Analysis
==============================================================

BASIC USAGE:
  python ROI_group.py --subjects_csv <GROUP_CSV> --clinical_csv <CLINICAL_CSV> --input_dir <FC_DATA_DIR>

QUICK EXAMPLES:
  1. Default Atlas (Auto-detect):
     python ROI_group.py \\
       --subjects_csv group.csv \\
       --clinical_csv clinical.csv \\
       --input_dir /path/to/fc/data

  2. Specific Atlas:
     python ROI_group.py \\
       --subjects_csv group.csv \\
       --clinical_csv clinical.csv \\
       --input_dir /path/to/fc/data \\
       --atlas_name schaefer_2018_400_7_2

  3. Custom Output Directory:
     python ROI_group.py \\
       --subjects_csv group.csv \\
       --clinical_csv clinical.csv \\
       --input_dir /path/to/fc/data \\
       --output_dir /custom/output/path

HELP OPTIONS:
  --help          Show full help with all arguments
  --usage         Show detailed usage examples

For more information, run with --usage or --help.
"""
    print(quick_help)

def print_examples():
    """Print detailed usage examples."""
    examples_text = """
DETAILED USAGE EXAMPLES
=======================

1. DEFAULT ATLAS (Auto-detect)
   ----------------------------
   This is the simplest usage, automatically detecting the atlas name from input files.
   
   python ROI_group.py \\
     --subjects_csv group.csv \\
     --clinical_csv clinical.csv \\
     --input_dir /path/to/fc/data
   
   Expected FC files: *_task-rest_{atlas_name}_roiroi_matrix_avg.npy

2. SPECIFIC ATLAS NAME
   --------------------
   Use when you know the exact atlas name from ROI_1st.py output.
   
   python ROI_group.py \\
     --subjects_csv group.csv \\
     --clinical_csv clinical.csv \\
     --input_dir /path/to/fc/data \\
     --atlas_name schaefer_2018_400_7_2
   
   Expected FC files: *_task-rest_schaefer_2018_400_7_2_roiroi_matrix_avg.npy

3. CUSTOM OUTPUT DIRECTORY
   ------------------------
   Override the default output directory.
   
   python ROI_group.py \\
     --subjects_csv group.csv \\
     --clinical_csv clinical.csv \\
     --input_dir /path/to/fc/data \\
     --output_dir /custom/output/path

4. CUSTOM INPUT DIRECTORY
   -----------------------
   Override the default input directory.
   
   python ROI_group.py \\
     --subjects_csv group.csv \\
     --clinical_csv clinical.csv \\
     --input_dir /custom/input/path

5. VERBOSE LOGGING
   ----------------
   Enable detailed logging for debugging.
   
   python ROI_group.py \\
     --subjects_csv group.csv \\
     --clinical_csv clinical.csv \\
     --input_dir /path/to/fc/data \\
     --verbose

REQUIRED FILES:
---------------
- group.csv: Contains subject IDs and group labels (HC/OCD)
  - Required columns: 'sub', 'group'
  - Example: sub-AOCD001,HC
- clinical.csv: Contains clinical data including YBOCS scores
  - Required columns: 'sub', 'ybocs_baseline', 'ybocs_followup'
  - Example: sub-AOCD001,25,18
- FC data files: Generated by ROI_1st.py with naming pattern:
  *_{session}_task-rest_{atlas_name}_roiroi_matrix_avg.npy

OUTPUT FILES:
-------------
- group_diff_baseline_{atlas_name}_roi_fc.csv: Group difference t-test results
- baselineFC_vs_deltaYBOCS_{atlas_name}_roi_fc.csv: Baseline FC vs symptom change
- deltaFC_vs_deltaYBOCS_{atlas_name}_roi_fc.csv: FC change vs symptom change

ATLAS NAMING CONVENTIONS:
-------------------------
The script automatically detects atlas names from input FC files:
- Power 2011: power_2011_roiroi_matrix_avg.npy
- Schaefer 2018: schaefer_2018_400_7_2_roiroi_matrix_avg.npy
- Custom: custom_atlas_roiroi_matrix_avg.npy

DIFFERENCE FROM NW_group.py:
----------------------------
This script analyzes ROI-to-ROI functional connectivity (individual ROI pairs),
while NW_group.py analyzes ROI-to-network connectivity. Both scripts work with
different types of FC data but provide complementary network analysis.

TROUBLESHOOTING:
----------------
1. Check that FC data files exist in the input directory
2. Verify atlas naming matches between ROI_1st.py and ROI_group.py
3. Ensure group.csv and clinical.csv have correct subject IDs
4. Use --verbose for detailed logging
5. Use --atlas_name to explicitly specify atlas if auto-detection fails

For more information, see the script docstring or run with --help.
"""
    print(examples_text)

if __name__ == "__main__":
    try:
        # Check for help requests first
        if len(sys.argv) > 1 and sys.argv[1] in ['--help', '-h', 'help']:
            print_quick_help()
            sys.exit(0)
        
        main()
    except Exception as e:
        logging.error("Main execution failed: %s", e)
        print(f"\nError: {e}")
        print("\nFor help, run: python ROI_group.py --help")
        print("For usage examples, run: python ROI_group.py --usage")
        raise